{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the metric for success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the context: Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relavance of our data will be answered by the following questions.\n",
    "\n",
    "How accurate is the data at predicting whether a patient has hypothyroidism or not?\n",
    "\n",
    "Was the dataset sufficient?\n",
    "\n",
    "Was the data biased?\n",
    "\n",
    "Is the data source a reliable source?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "from io import open\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Flatten, GlobalMaxPooling2D\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the train data\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification task. Let us check the number of classes that we are aiming to classify the data into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "       16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ClassId.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 43 unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the test data\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version  \n",
      "---------------------------------- ---------\n",
      "absl-py                            0.8.1    \n",
      "alabaster                          0.7.12   \n",
      "anaconda-client                    1.7.2    \n",
      "anaconda-navigator                 1.9.7    \n",
      "anaconda-project                   0.8.3    \n",
      "asn1crypto                         1.0.1    \n",
      "astor                              0.8.0    \n",
      "astroid                            2.3.1    \n",
      "astropy                            3.2.1    \n",
      "atomicwrites                       1.3.0    \n",
      "attrs                              19.2.0   \n",
      "autopep8                           1.5      \n",
      "Babel                              2.7.0    \n",
      "backcall                           0.1.0    \n",
      "backports.functools-lru-cache      1.6.1    \n",
      "backports.os                       0.1.1    \n",
      "backports.shutil-get-terminal-size 1.0.0    \n",
      "backports.tempfile                 1.0      \n",
      "backports.weakref                  1.0.post1\n",
      "beautifulsoup4                     4.8.0    \n",
      "bitarray                           1.0.1    \n",
      "bkcharts                           0.2      \n",
      "bleach                             3.1.0    \n",
      "bokeh                              1.3.4    \n",
      "boto                               2.49.0   \n",
      "Bottleneck                         1.2.1    \n",
      "certifi                            2019.9.11\n",
      "cffi                               1.12.3   \n",
      "chardet                            3.0.4    \n",
      "Click                              7.0      \n",
      "cloudpickle                        1.2.2    \n",
      "clyent                             1.2.2    \n",
      "colorama                           0.4.1    \n",
      "comtypes                           1.1.7    \n",
      "conda                              4.8.2    \n",
      "conda-build                        3.18.9   \n",
      "conda-package-handling             1.6.0    \n",
      "conda-verify                       3.4.2    \n",
      "contextlib2                        0.6.0    \n",
      "cryptography                       2.7      \n",
      "cycler                             0.10.0   \n",
      "Cython                             0.29.13  \n",
      "cytoolz                            0.10.0   \n",
      "dask                               2.5.2    \n",
      "decorator                          4.4.0    \n",
      "defusedxml                         0.6.0    \n",
      "distributed                        2.5.2    \n",
      "docutils                           0.15.2   \n",
      "entrypoints                        0.3      \n",
      "et-xmlfile                         1.0.1    \n",
      "fastcache                          1.1.0    \n",
      "filelock                           3.0.12   \n",
      "Flask                              1.1.1    \n",
      "fsspec                             0.5.2    \n",
      "future                             0.18.2   \n",
      "gast                               0.2.2    \n",
      "gevent                             1.4.0    \n",
      "glob2                              0.7      \n",
      "google-pasta                       0.1.8    \n",
      "greenlet                           0.4.15   \n",
      "grpcio                             1.16.1   \n",
      "h5py                               2.9.0    \n",
      "HeapDict                           1.0.1    \n",
      "html5lib                           1.0.1    \n",
      "idna                               2.8      \n",
      "imageio                            2.6.0    \n",
      "imagesize                          1.1.0    \n",
      "importlib-metadata                 0.23     \n",
      "ipykernel                          5.1.2    \n",
      "ipyparallel                        6.2.4    \n",
      "ipython                            7.8.0    \n",
      "ipython-genutils                   0.2.0    \n",
      "ipywidgets                         7.5.1    \n",
      "isort                              4.3.21   \n",
      "itsdangerous                       1.1.0    \n",
      "jdcal                              1.4.1    \n",
      "jedi                               0.15.1   \n",
      "Jinja2                             2.10.3   \n",
      "joblib                             0.13.2   \n",
      "json5                              0.8.5    \n",
      "jsonschema                         3.0.2    \n",
      "jupyter                            1.0.0    \n",
      "jupyter-client                     5.3.3    \n",
      "jupyter-console                    6.0.0    \n",
      "jupyter-contrib-core               0.3.3    \n",
      "jupyter-contrib-nbextensions       0.5.1    \n",
      "jupyter-core                       4.5.0    \n",
      "jupyter-highlight-selected-word    0.2.0    \n",
      "jupyter-latex-envs                 1.4.6    \n",
      "jupyter-nbextensions-configurator  0.4.1    \n",
      "jupyterlab                         1.1.4    \n",
      "jupyterlab-server                  1.0.6    \n",
      "Keras                              2.2.4    \n",
      "Keras-Applications                 1.0.8    \n",
      "Keras-Preprocessing                1.1.0    \n",
      "keyring                            18.0.0   \n",
      "kiwisolver                         1.1.0    \n",
      "lazy-object-proxy                  1.4.2    \n",
      "libarchive-c                       2.8      \n",
      "llvmlite                           0.29.0   \n",
      "locket                             0.2.0    \n",
      "lxml                               4.4.1    \n",
      "Markdown                           3.1.1    \n",
      "MarkupSafe                         1.1.1    \n",
      "matplotlib                         3.1.1    \n",
      "mccabe                             0.6.1    \n",
      "menuinst                           1.4.16   \n",
      "mistune                            0.8.4    \n",
      "mkl-fft                            1.0.14   \n",
      "mkl-random                         1.1.0    \n",
      "mkl-service                        2.3.0    \n",
      "mock                               3.0.5    \n",
      "more-itertools                     7.2.0    \n",
      "mpmath                             1.1.0    \n",
      "msgpack                            0.6.1    \n",
      "multipledispatch                   0.6.0    \n",
      "navigator-updater                  0.2.1    \n",
      "nbconvert                          5.6.0    \n",
      "nbformat                           4.4.0    \n",
      "networkx                           2.3      \n",
      "nltk                               3.4.5    \n",
      "nose                               1.3.7    \n",
      "notebook                           6.0.1    \n",
      "numba                              0.45.1   \n",
      "numexpr                            2.7.0    \n",
      "numpy                              1.16.5   \n",
      "numpydoc                           0.9.1    \n",
      "olefile                            0.46     \n",
      "opencv-python                      4.2.0.32 \n",
      "openpyxl                           3.0.0    \n",
      "opt-einsum                         3.1.0    \n",
      "packaging                          19.2     \n",
      "pandas                             0.25.1   \n",
      "pandocfilters                      1.4.2    \n",
      "parso                              0.5.1    \n",
      "partd                              1.0.0    \n",
      "path.py                            12.0.1   \n",
      "pathlib2                           2.3.5    \n",
      "patsy                              0.5.1    \n",
      "pep8                               1.7.1    \n",
      "pickleshare                        0.7.5    \n",
      "Pillow                             6.2.0    \n",
      "pip                                19.2.3   \n",
      "pkginfo                            1.5.0.1  \n",
      "pluggy                             0.13.0   \n",
      "ply                                3.11     \n",
      "prometheus-client                  0.7.1    \n",
      "prompt-toolkit                     2.0.10   \n",
      "protobuf                           3.11.2   \n",
      "psutil                             5.6.3    \n",
      "py                                 1.8.0    \n",
      "pycodestyle                        2.5.0    \n",
      "pycosat                            0.6.3    \n",
      "pycparser                          2.19     \n",
      "pycrypto                           2.6.1    \n",
      "pycurl                             7.43.0.3 \n",
      "pydataset                          0.2.0    \n",
      "pyflakes                           2.1.1    \n",
      "Pygments                           2.4.2    \n",
      "pylint                             2.4.2    \n",
      "pyodbc                             4.0.27   \n",
      "pyOpenSSL                          19.0.0   \n",
      "pyparsing                          2.4.2    \n",
      "pyreadline                         2.1      \n",
      "pyrsistent                         0.15.4   \n",
      "PySocks                            1.7.1    \n",
      "pytest                             5.2.1    \n",
      "pytest-arraydiff                   0.3      \n",
      "pytest-astropy                     0.5.0    \n",
      "pytest-doctestplus                 0.4.0    \n",
      "pytest-openfiles                   0.4.0    \n",
      "pytest-remotedata                  0.3.2    \n",
      "python-dateutil                    2.8.0    \n",
      "pytz                               2019.3   \n",
      "PyWavelets                         1.0.3    \n",
      "pywin32                            223      \n",
      "pywinpty                           0.5.5    \n",
      "PyYAML                             5.1.2    \n",
      "pyzmq                              18.1.0   \n",
      "QtAwesome                          0.6.0    \n",
      "qtconsole                          4.5.5    \n",
      "QtPy                               1.9.0    \n",
      "requests                           2.22.0   \n",
      "rope                               0.14.0   \n",
      "ruamel-yaml                        0.15.46  \n",
      "scikit-image                       0.15.0   \n",
      "scikit-learn                       0.21.3   \n",
      "scipy                              1.3.1    \n",
      "seaborn                            0.9.0    \n",
      "Send2Trash                         1.5.0    \n",
      "setuptools                         41.4.0   \n",
      "simplegeneric                      0.8.1    \n",
      "singledispatch                     3.4.0.3  \n",
      "six                                1.12.0   \n",
      "snowballstemmer                    2.0.0    \n",
      "sortedcollections                  1.1.2    \n",
      "sortedcontainers                   2.1.0    \n",
      "soupsieve                          1.9.3    \n",
      "Sphinx                             2.2.0    \n",
      "sphinxcontrib-applehelp            1.0.1    \n",
      "sphinxcontrib-devhelp              1.0.1    \n",
      "sphinxcontrib-htmlhelp             1.0.2    \n",
      "sphinxcontrib-jsmath               1.0.1    \n",
      "sphinxcontrib-qthelp               1.0.2    \n",
      "sphinxcontrib-serializinghtml      1.1.3    \n",
      "sphinxcontrib-websupport           1.1.2    \n",
      "spyder                             3.3.6    \n",
      "spyder-kernels                     0.5.2    \n",
      "SQLAlchemy                         1.3.9    \n",
      "statsmodels                        0.10.1   \n",
      "sympy                              1.4      \n",
      "tables                             3.5.2    \n",
      "tblib                              1.4.0    \n",
      "tensorboard                        2.0.0    \n",
      "tensorflow                         1.15.0   \n",
      "tensorflow-estimator               1.15.1   \n",
      "termcolor                          1.1.0    \n",
      "terminado                          0.8.2    \n",
      "testpath                           0.4.2    \n",
      "toolz                              0.10.0   \n",
      "tornado                            6.0.3    \n",
      "tqdm                               4.36.1   \n",
      "traitlets                          4.3.3    \n",
      "unicodecsv                         0.14.1   \n",
      "urllib3                            1.24.2   \n",
      "wcwidth                            0.1.7    \n",
      "webencodings                       0.5.1    \n",
      "Werkzeug                           0.16.0   \n",
      "wheel                              0.33.6   \n",
      "widgetsnbextension                 3.5.1    \n",
      "win-inet-pton                      1.1.0    \n",
      "win-unicode-console                0.5      \n",
      "wincertstore                       0.2      \n",
      "wrapt                              1.11.2   \n",
      "xlrd                               1.2.0    \n",
      "XlsxWriter                         1.2.1    \n",
      "xlwings                            0.15.10  \n",
      "xlwt                               1.3.0    \n",
      "zict                               1.0.0    \n",
      "zipp                               0.6.0    \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### properties of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shape of the train dataset\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12630, 8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ClassId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ClassId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us view the data distribution in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x00000245813D8408>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram to show the distribution of a column\n",
    "train.hist(column='ClassId', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are located in the same directory as the notebook. we need to specify the path to locate the images\n",
    "so that we can read the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'German Traffic Signs Image Classification.ipynb', 'Meta', 'Meta.csv', 'Test', 'Test.csv', 'Train', 'Train.csv']\n"
     ]
    }
   ],
   "source": [
    "#specifying the path and printing the document names\n",
    "print(os.listdir('../Image Classification Task Kaggle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we put the images in an array in order to read and load them into our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Image Classification Task Kaggle/Train/0/\n",
      "../Image Classification Task Kaggle/Train/1/\n",
      "../Image Classification Task Kaggle/Train/2/\n",
      "../Image Classification Task Kaggle/Train/3/\n",
      "../Image Classification Task Kaggle/Train/4/\n",
      "../Image Classification Task Kaggle/Train/5/\n",
      "../Image Classification Task Kaggle/Train/6/\n",
      "../Image Classification Task Kaggle/Train/7/\n",
      "../Image Classification Task Kaggle/Train/8/\n",
      "../Image Classification Task Kaggle/Train/9/\n",
      "../Image Classification Task Kaggle/Train/10/\n",
      "../Image Classification Task Kaggle/Train/11/\n",
      "../Image Classification Task Kaggle/Train/12/\n",
      "../Image Classification Task Kaggle/Train/13/\n",
      "../Image Classification Task Kaggle/Train/14/\n",
      "../Image Classification Task Kaggle/Train/15/\n",
      "../Image Classification Task Kaggle/Train/16/\n",
      "../Image Classification Task Kaggle/Train/17/\n",
      "../Image Classification Task Kaggle/Train/18/\n",
      "../Image Classification Task Kaggle/Train/19/\n",
      "../Image Classification Task Kaggle/Train/20/\n",
      "../Image Classification Task Kaggle/Train/21/\n",
      "../Image Classification Task Kaggle/Train/22/\n",
      "../Image Classification Task Kaggle/Train/23/\n",
      "../Image Classification Task Kaggle/Train/24/\n",
      "../Image Classification Task Kaggle/Train/25/\n",
      "../Image Classification Task Kaggle/Train/26/\n",
      "../Image Classification Task Kaggle/Train/27/\n",
      "../Image Classification Task Kaggle/Train/28/\n",
      "../Image Classification Task Kaggle/Train/29/\n",
      "../Image Classification Task Kaggle/Train/30/\n",
      "../Image Classification Task Kaggle/Train/31/\n",
      "../Image Classification Task Kaggle/Train/32/\n",
      "../Image Classification Task Kaggle/Train/33/\n",
      "../Image Classification Task Kaggle/Train/34/\n",
      "../Image Classification Task Kaggle/Train/35/\n",
      "../Image Classification Task Kaggle/Train/36/\n",
      "../Image Classification Task Kaggle/Train/37/\n",
      "../Image Classification Task Kaggle/Train/38/\n",
      "../Image Classification Task Kaggle/Train/39/\n",
      "../Image Classification Task Kaggle/Train/40/\n",
      "../Image Classification Task Kaggle/Train/41/\n",
      "../Image Classification Task Kaggle/Train/42/\n"
     ]
    }
   ],
   "source": [
    "# Reading the input images and putting them into a numpy array\n",
    "#the data array stores the images without the labels and the labels array stores the image label\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "#resizing the images to 30 by 30\n",
    "height = 30\n",
    "width = 30\n",
    "#The channe\n",
    "channels = 3\n",
    "num_classes = 43\n",
    "n_inputs = height * width*channels\n",
    "\n",
    "for i in range(num_classes) :\n",
    "    path = \"../Image Classification Task Kaggle/Train/{0}/\".format(i)\n",
    "    print(path)\n",
    "    Class=os.listdir(path)\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a)\n",
    "            image_from_array = Image.fromarray(image, 'RGB')\n",
    "            size_image = image_from_array.resize((height, width))\n",
    "            data.append(np.array(size_image))\n",
    "            labels.append(i)\n",
    "        except AttributeError:\n",
    "            print(\" \")\n",
    "            \n",
    "x_train=np.array(data)\n",
    "x_train= x_train/255.0\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train=np.array(labels)\n",
    "y_train = to_categorical(y_train, num_classes) # Using one hote encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.34208195, 0.41073748, 0.40526098, 0.64669306, 0.46052384,\n",
       "       0.49023506, 2.17104097, 0.63322028, 0.64669306, 0.62029742,\n",
       "       0.45365035, 0.69078576, 0.43420819, 0.42214686, 1.16902206,\n",
       "       1.44736065, 2.17104097, 0.82147496, 0.75986434, 4.34208195,\n",
       "       2.53288114, 2.76314306, 2.33804413, 1.7879161 , 3.37717485,\n",
       "       0.60789147, 1.51972868, 3.79932171, 1.68858742, 3.37717485,\n",
       "       2.02630491, 1.16902206, 3.79932171, 1.3234212 , 2.17104097,\n",
       "       0.75986434, 2.33804413, 4.34208195, 0.44050107, 3.03945736,\n",
       "       2.53288114, 3.79932171, 3.79932171])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(labels),\n",
    "                                                        labels)\n",
    "\n",
    "print(np.unique(labels))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data is ready for training. we will use the train  data for training and validation,\n",
    "after which, we will subject the model to test data to rate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (27446, 30, 30, 3)\n",
      "Validation : (11763, 30, 30, 3)\n",
      "Train : (27446, 43)\n",
      "Validation : (11763, 43)\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_validation,Y_train,Y_validation = train_test_split(x_train,y_train,test_size = 0.3,random_state=0)\n",
    "\n",
    "print(\"Train :\", X_train.shape)\n",
    "print(\"Validation :\", X_validation.shape)\n",
    "print(\"Train :\", Y_train.shape)\n",
    "print(\"Validation :\", Y_validation.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed to modelling, let us preview some random images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of this image is (30, 30, 3)\n",
      "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of this image is (30, 30, 3)\n",
      "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of this image is (30, 30, 3)\n",
      "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def show_images(images, labels, amount):\n",
    "    for i in range(amount):\n",
    "        index = int(random.random() * len(images))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[index])\n",
    "        plt.show()       \n",
    "        print(\"Size of this image is \" + str(images[index].shape))\n",
    "        print(\"Class of the image is \" + str(labels[index]))\n",
    "\n",
    "print(\"Train images\")\n",
    "show_images(X_train, Y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 879,691\n",
      "Trainable params: 879,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model and give the model summary\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dropout, Dense\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compiling\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 10 epochs(iterations to train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27446 samples, validate on 11763 samples\n",
      "Epoch 1/10\n",
      "25440/27446 [==========================>...] - ETA: 8s - loss: 1.5313 - acc: 0.5579"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "epochs = 10\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_validation, Y_validation), batch_size=32,\n",
    "                    epochs=epochs,verbose=1,class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the accuracy and the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenging the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed for our Cats & Dogs classes\n",
    "NUM_CLASSES = 43\n",
    "\n",
    "# Fixed for Cats & Dogs color images\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 128\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 50\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_VALIDATION = 10\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 100\n",
    "BATCH_SIZE_VALIDATION = 100\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "TL_model = ResNet50(weights='imagenet',\n",
    "                      pooling = RESNET50_POOLING_AVERAGE,\n",
    "                          include_top=False, \n",
    "                          input_shape=(128,128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the pretrained model\n",
    "history_TL = model.fit(X_train, Y_train, validation_data=(X_validation, Y_validation), batch_size=32,\n",
    "                    epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the accuracy and the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history_TL.history['acc'], label='training accuracy')\n",
    "plt.plot(history_TL.history['val_acc'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history_TL.history['loss'], label='training loss')\n",
    "plt.plot(history_TL.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with Test data \n",
    "y_test=pd.read_csv(\"../Image Classification Task Kaggle/Test.csv\")\n",
    "labels=y_test['Path'].as_matrix()\n",
    "y_test=y_test['ClassId'].values\n",
    "\n",
    "data=[]\n",
    "\n",
    "for f in labels:\n",
    "    image=cv2.imread('../Image Classification Task Kaggle/Test/'+f.replace('Test/', ''))\n",
    "    image_from_array = Image.fromarray(image, 'RGB')\n",
    "    size_image = image_from_array.resize((height, width))\n",
    "    data.append(np.array(size_image))\n",
    "\n",
    "X_test=np.array(data)\n",
    "X_test = X_test.astype('float32')/255  \n",
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test , pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=75) \n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "class_names = range(43)\n",
    "cm = confusion_matrix(pred,y_test)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "168.99px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
